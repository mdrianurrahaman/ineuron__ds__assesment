{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# question 2 \n",
        "Train a Pure ANN with less than 10000 trainable parameters using the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ADzOYOHPFBkf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xuYEjizYFP2j"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RbRN1nPFSQL",
        "outputId": "a1194446-de0e-4d00-f366-02fa50d2ad75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109386 (427.29 KB)\n",
            "Trainable params: 109386 (427.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09-m86q7GZi0",
        "outputId": "73a23337-5529-488a-f3e4-8060befdfb72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3863 - accuracy: 0.8908 - val_loss: 0.1944 - val_accuracy: 0.9439\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1589 - accuracy: 0.9543 - val_loss: 0.1437 - val_accuracy: 0.9574\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1117 - accuracy: 0.9665 - val_loss: 0.1152 - val_accuracy: 0.9653\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.0844 - accuracy: 0.9747 - val_loss: 0.1026 - val_accuracy: 0.9699\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0668 - accuracy: 0.9799 - val_loss: 0.0962 - val_accuracy: 0.9716\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 0.0962 - val_accuracy: 0.9712\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.0961 - val_accuracy: 0.9714\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0883 - val_accuracy: 0.9742\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0929 - val_accuracy: 0.9755\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9924 - val_loss: 0.0994 - val_accuracy: 0.9729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b108065b400>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9P3xFxGcoT",
        "outputId": "6b49eb30-4eb2-4c60-a1b5-76eb43c648fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9734\n",
            "Test accuracy: 0.9733999967575073\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uKHnCyxGlg-"
      },
      "source": [
        "\n",
        "Certainly! We can design a simple feedforward neural network (also known as an Artificial Neural Network, or ANN) with a small number of parameters for the MNIST dataset.\n",
        "\n",
        "Here's an example of a pure ANN with less than 10,000 trainable parameters:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Flatten the images\n",
        "X_train = X_train.reshape((X_train.shape[0], -1))\n",
        "X_test = X_test.reshape((X_test.shape[0], -1))\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "This model has the following architecture:\n",
        "\n",
        "Input layer: 784 neurons (28x28 pixels flattened)\n",
        "Hidden layer 1: 128 neurons with ReLU activation function\n",
        "Hidden layer 2: 64 neurons with ReLU activation function\n",
        "Output layer: 10 neurons with softmax activation function (since we have 10 classes in MNIST)\n",
        "Let's calculate the number of parameters:\n",
        "\n",
        "Input layer to Hidden layer 1: (784 input neurons + 1 bias) * 128 neurons = 100480 parameters\n",
        "Hidden layer 1 to Hidden layer 2: (128 neurons + 1 bias) * 64 neurons = 8256 parameters\n",
        "Hidden layer 2 to Output layer: (64 neurons + 1 bias) * 10 neurons = 650 parameters\n",
        "Total parameters = 100480 + 8256 + 650 = 109386 parameters, which is above 10,000. Let's reduce the size of the hidden layers to meet the requirement. We could change the number of neurons in each hidden layer to 64 and 32, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZCFxUhDGzJT"
      },
      "source": [
        "Updated model which is good on mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWBb8JM1Gnd_",
        "outputId": "4d6b2833-58bc-4459-a943-5e26f3995554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52650 (205.66 KB)\n",
            "Trainable params: 52650 (205.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model with reduced parameters\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(784,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
